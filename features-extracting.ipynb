{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12265941,"sourceType":"datasetVersion","datasetId":7690296},{"sourceId":12266794,"sourceType":"datasetVersion","datasetId":7729987}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ติดตั้ง mediapipe แบบเงียบๆ (-q)\n!pip install mediapipe opencv-python tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T13:53:13.944685Z","iopub.execute_input":"2025-07-05T13:53:13.945078Z","iopub.status.idle":"2025-07-05T13:53:38.994514Z","shell.execute_reply.started":"2025-07-05T13:53:13.945036Z","shell.execute_reply":"2025-07-05T13:53:38.993314Z"}},"outputs":[{"name":"stdout","text":"Collecting mediapipe\n  Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\nRequirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\nRequirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\nRequirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\nRequirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.7.2)\nRequirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.26.4)\nRequirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\nCollecting protobuf<5,>=4.25.3 (from mediapipe)\n  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\nCollecting sounddevice>=0.4.4 (from mediapipe)\n  Downloading sounddevice-0.5.2-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2->mediapipe) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2->mediapipe) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2->mediapipe) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2->mediapipe) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2->mediapipe) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2->mediapipe) (2.4.1)\nRequirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\nRequirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\nRequirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\nRequirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.15.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2->mediapipe) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2->mediapipe) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2->mediapipe) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2->mediapipe) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2->mediapipe) (2024.2.0)\nDownloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl (35.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sounddevice-0.5.2-py3-none-any.whl (32 kB)\nInstalling collected packages: protobuf, sounddevice, mediapipe\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 4.25.8 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngoogle-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-bigtable 2.30.0 requires google-api-core[grpc]<3.0.0,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed mediapipe-0.10.21 protobuf-4.25.8 sounddevice-0.5.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import cv2\nimport mediapipe as mp\nimport numpy as np\nimport os\nfrom mediapipe.tasks import python\nfrom mediapipe.tasks.python import vision\n# from mediapipe.tasks.python.core.base_options import BaseOptions, Delegate\nfrom tqdm.auto import tqdm # <-- 1. เพิ่มการ import tqdm.auto\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-05T13:53:38.995854Z","iopub.execute_input":"2025-07-05T13:53:38.996242Z","iopub.status.idle":"2025-07-05T13:53:56.963520Z","shell.execute_reply.started":"2025-07-05T13:53:38.996189Z","shell.execute_reply":"2025-07-05T13:53:56.962340Z"}},"outputs":[{"name":"stderr","text":"2025-07-05 13:53:41.395459: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751723621.619559      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751723621.691490      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"MODEL_PATH = '/kaggle/input/mediapipe/face_landmarker.task'\n\nBASE_INPUT_PATH = '/kaggle/input/ferplus/FER2013' \n\nBASE_OUTPUT_PATH = '/kaggle/working/output'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T13:53:56.966392Z","iopub.execute_input":"2025-07-05T13:53:56.966949Z","iopub.status.idle":"2025-07-05T13:53:56.972389Z","shell.execute_reply.started":"2025-07-05T13:53:56.966924Z","shell.execute_reply":"2025-07-05T13:53:56.971166Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"csv_path = \"/kaggle/input/ferplus/fer2013new.csv\"\ndf = pd.read_csv(csv_path)\n\n# กรอง: ไม่เอา contempt กับ NF\ndf = df[(df['contempt'] == 0) & (df['NF'] == 0)].copy()\n\n# อารมณ์ 7 แบบที่เราจะใช้\nemotion_cols = ['neutral', 'happiness', 'surprise', 'sadness', 'anger', 'disgust', 'fear']\ndf['label'] = df[emotion_cols].idxmax(axis=1)\n\n# จัดชื่อคอลัมน์และ split\ndf = df.rename(columns={'Image name': 'filename', 'Usage': 'split'})\ndf['filename'] = df['filename'].str.strip()\ndf['split'] = df['split'].replace({\n    'Training': 'train',\n    'PublicTest': 'valid',\n    'PrivateTest': 'test'\n})\n\n# เก็บเฉพาะคอลัมน์ที่ต้องใช้\ndf_final = df[['filename', 'label', 'split']]\n\n# บันทึกลงไฟล์ใน Kaggle Working Directory\ndf_final.to_csv(\"/kaggle/working/index_with_labels.csv\", index=False)\n\n# ตรวจสอบ\ndf_final.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T13:53:56.973417Z","iopub.execute_input":"2025-07-05T13:53:56.973734Z","iopub.status.idle":"2025-07-05T13:53:57.233779Z","shell.execute_reply.started":"2025-07-05T13:53:56.973713Z","shell.execute_reply":"2025-07-05T13:53:57.232508Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"         filename    label  split\n0  fer0000000.png  neutral  train\n1  fer0000001.png  neutral  train\n2  fer0000002.png  neutral  train\n3  fer0000003.png  neutral  train\n4  fer0000004.png  neutral  train","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>label</th>\n      <th>split</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>fer0000000.png</td>\n      <td>neutral</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fer0000001.png</td>\n      <td>neutral</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>fer0000002.png</td>\n      <td>neutral</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>fer0000003.png</td>\n      <td>neutral</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>fer0000004.png</td>\n      <td>neutral</td>\n      <td>train</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"IMPORTANT_LANDMARK_INDICES = {\n    # ริมฝีปาก (Lips)\n    78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308,\n    95, 88, 178, 87, 14, 317, 402, 318, 324,\n    61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291,\n    146, 91, 181, 84, 17, 314, 405, 321, 375,\n    # ตาซ้าย (Left Eye)\n    33, 7, 163, 144, 145, 153, 154, 155, 133,\n    246, 161, 160, 159, 158, 157, 173,\n    # คิ้วซ้าย (Left Eyebrow)\n    70, 63, 105, 66, 107, 55, 65, 52, 53, 46,\n    # ตาขวา (Right Eye)\n    263, 249, 390, 373, 374, 380, 381, 382, 362,\n    466, 388, 387, 386, 385, 384, 398,\n    # คิ้วขวา (Right Eyebrow)\n    300, 293, 334, 296, 336, 285, 295, 282, 283, 276\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T13:53:57.234987Z","iopub.execute_input":"2025-07-05T13:53:57.235812Z","iopub.status.idle":"2025-07-05T13:53:57.242577Z","shell.execute_reply.started":"2025-07-05T13:53:57.235779Z","shell.execute_reply":"2025-07-05T13:53:57.241460Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def create_landmarker():\n    base_options = python.BaseOptions(model_asset_path=MODEL_PATH)\n    options = vision.FaceLandmarkerOptions(base_options=base_options, running_mode=vision.RunningMode.IMAGE, num_faces=1)\n    print(\"สร้าง Landmarker สำหรับ CPU สำเร็จ\")\n    return vision.FaceLandmarker.create_from_options(options)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T13:53:57.243862Z","iopub.execute_input":"2025-07-05T13:53:57.244223Z","iopub.status.idle":"2025-07-05T13:53:57.268593Z","shell.execute_reply.started":"2025-07-05T13:53:57.244190Z","shell.execute_reply":"2025-07-05T13:53:57.267323Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def extract_landmarks_data(rgb_image, detection_result):\n    extracted_faces_data = []\n    if not detection_result.face_landmarks:\n        return extracted_faces_data\n\n    height, width, _ = rgb_image.shape\n\n    for face_landmarks in detection_result.face_landmarks:\n        # Store landmarks as a NumPy array (N, 3) for x, y, and z\n        important_landmarks_array = []\n        important_landmarks_indices_list = []\n\n        for i, landmark in enumerate(face_landmarks):\n            if i in IMPORTANT_LANDMARK_INDICES:\n                # 1. ดึงค่า z เพิ่มเข้ามา\n                # ค่า z ของ MediaPipe บอกความลึก โดยมีจุดศูนย์กลางของศีรษะเป็น origin\n                # เราจะคูณด้วย width เพื่อให้สเกลใกล้เคียงกับ x และ y\n                x = int(landmark.x * width)\n                y = int(landmark.y * height)\n                z = int(landmark.z * width) # ดึงค่า z และแปลงเป็นพิกัด\n\n                # (สำคัญ) เพิ่ม z เข้าไปใน array\n                important_landmarks_array.append([x, y, z])\n                important_landmarks_indices_list.append(i)\n\n        # Convert to numpy array, shape will now be (N, 3)\n        important_landmarks_array = np.array(important_landmarks_array, dtype=np.int32)\n        important_landmarks_indices_array = np.array(important_landmarks_indices_list, dtype=np.int32)\n\n        # Store connections as a NumPy array (M, 6)\n        # Each row: [start_x, start_y, start_z, end_x, end_y, end_z]\n        important_connections_array = []\n        \n        # Create a quick lookup for landmark coordinates by index\n        landmark_coords_map = {idx: coord for idx, coord in zip(important_landmarks_indices_list, important_landmarks_array)}\n\n        connections = mp.solutions.face_mesh.FACEMESH_TESSELATION\n        for connection in connections:\n            start_idx, end_idx = connection\n\n            if start_idx in IMPORTANT_LANDMARK_INDICES and end_idx in IMPORTANT_LANDMARK_INDICES:\n                if start_idx in landmark_coords_map and end_idx in landmark_coords_map:\n                    # 2. แก้ไขการดึงข้อมูลจาก map ให้รองรับ z ( unpacking 3 values)\n                    start_x, start_y, start_z = landmark_coords_map[start_idx]\n                    end_x, end_y, end_z = landmark_coords_map[end_idx]\n                    \n                    # 3. เพิ่มพิกัด z ของจุดเริ่มต้นและสิ้นสุดเข้าไปใน array\n                    important_connections_array.append([start_x, start_y, start_z, end_x, end_y, end_z])\n        \n        important_connections_array = np.array(important_connections_array, dtype=np.int32)\n\n        extracted_faces_data.append({\n            'important_landmarks_coords': important_landmarks_array,\n            'important_landmarks_indices': important_landmarks_indices_array,\n            'important_connections_coords': important_connections_array\n        })\n    return extracted_faces_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T13:53:57.270363Z","iopub.execute_input":"2025-07-05T13:53:57.270823Z","iopub.status.idle":"2025-07-05T13:53:57.294049Z","shell.execute_reply.started":"2025-07-05T13:53:57.270786Z","shell.execute_reply":"2025-07-05T13:53:57.292925Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def process_images_in_folder(landmarker, dataframe, base_input_path, output_filename=\"all_data_with_landmarks.npz\"):\n    all_landmarks = []\n    all_landmark_indices = []\n    all_connections = []\n    all_labels = []\n    all_splits = []\n    all_filenames = []\n\n    print(f\"\\n--- เริ่มประมวลผลรูปภาพทั้งหมดและรวมเป็นไฟล์เดียว ---\")\n    # Iterate through each row of the DataFrame\n    for index, row in tqdm(dataframe.iterrows(), total=len(dataframe), desc=\"Processing images\"):\n        filename = row['filename']\n        label = row['label']\n        split = row['split']\n\n        # Determine the correct subfolder based on the 'split' column\n        if split.lower() == 'train':\n            input_folder = os.path.join(base_input_path, 'FER2013TRAIN')\n        elif split.lower() == 'test':\n            input_folder = os.path.join(base_input_path, 'FER2013TEST')\n        elif split.lower() == 'valid': # Assuming 'valid' for validation set\n            input_folder = os.path.join(base_input_path, 'FER2013VALID')\n        else:\n            print(f\"คำเตือน: ไม่รู้จัก split type '{split}' สำหรับไฟล์ '{filename}'. ข้าม.\")\n            continue\n\n        input_image_path = os.path.join(input_folder, filename)\n\n        if not os.path.exists(input_image_path):\n            print(f\"คำเตือน: ไม่พบไฟล์รูปภาพที่: {input_image_path}. ข้าม.\")\n            continue\n\n        image_bgr = cv2.imread(input_image_path)\n        if image_bgr is None:\n            print(f\"คำเตือน: ไม่สามารถอ่านรูปภาพได้: {input_image_path}. ข้าม.\")\n            continue\n        \n        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=image_rgb)\n        detection_result = landmarker.detect(mp_image)\n        \n        extracted_data = extract_landmarks_data(image_rgb, detection_result)\n        \n        if extracted_data: # Only process if a face was detected\n            face_data = extracted_data[0] # Assuming one face per image\n            all_landmarks.append(face_data['important_landmarks_coords'])\n            all_landmark_indices.append(face_data['important_landmarks_indices'])\n            all_connections.append(face_data['important_connections_coords'])\n            all_labels.append(label)\n            all_splits.append(split)\n            all_filenames.append(filename)\n        # else:\n            # print(f\"ไม่พบใบหน้าใน {filename}, ข้อมูล landmark จะไม่ถูกบันทึกสำหรับรูปภาพนี้\")\n\n    # Create output directory if it doesn't exist\n    if not os.path.exists(BASE_OUTPUT_PATH):\n        os.makedirs(BASE_OUTPUT_PATH)\n        print(f\"สร้างโฟลเดอร์ผลลัพธ์: {BASE_OUTPUT_PATH}\")\n\n    output_filepath = os.path.join(BASE_OUTPUT_PATH, output_filename)\n    \n    # Save all collected data into a single .npz file\n    np.savez_compressed(output_filepath,\n                       landmarks=np.array(all_landmarks, dtype=object), # Use dtype=object for variable-length arrays\n                       landmark_indices=np.array(all_landmark_indices, dtype=object),\n                       connections=np.array(all_connections, dtype=object),\n                       labels=np.array(all_labels),\n                       splits=np.array(all_splits),\n                       filenames=np.array(all_filenames))\n\n    print(f\"\\nบันทึกข้อมูล Landmarker, label, และ split ทั้งหมดลงในไฟล์: '{output_filepath}' สำเร็จ\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T14:00:55.180162Z","iopub.execute_input":"2025-07-05T14:00:55.180560Z","iopub.status.idle":"2025-07-05T14:00:55.194616Z","shell.execute_reply.started":"2025-07-05T14:00:55.180535Z","shell.execute_reply":"2025-07-05T14:00:55.193223Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def main():\n    if not os.path.exists(MODEL_PATH):\n        print(f\"!!! ไม่พบไฟล์โมเดลที่: '{MODEL_PATH}'\")\n        print(\"โปรดดาวน์โหลดโมเดล Face Landmarker จาก MediaPipe และระบุ MODEL_PATH ให้ถูกต้อง\")\n        print(\"ตัวอย่าง: https://developers.google.com/mediapipe/solutions/vision/face_landmarker#models\")\n        return\n    if not os.path.exists(BASE_INPUT_PATH):\n        print(f\"!!! ไม่พบโฟลเดอร์ข้อมูลที่: '{BASE_INPUT_PATH}'\")\n        print(\"โปรดตรวจสอบ BASE_INPUT_PATH ให้ถูกต้อง (e.g., 'data/FER2013')\")\n        return\n    landmarker = create_landmarker()\n    \n    # Process all images and save to a single .npz file\n    process_images_in_folder(landmarker, df_final, BASE_INPUT_PATH)\n\n    landmarker.close()\n    print(f\"\\nการประมวลผลทั้งหมดเสร็จสิ้น! ตรวจสอบไฟล์ข้อมูลพิกัด (ในรูปแบบ .npz) ได้ที่โฟลเดอร์ '{BASE_OUTPUT_PATH}'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T14:00:57.606861Z","iopub.execute_input":"2025-07-05T14:00:57.607253Z","iopub.status.idle":"2025-07-05T14:00:57.615188Z","shell.execute_reply.started":"2025-07-05T14:00:57.607226Z","shell.execute_reply":"2025-07-05T14:00:57.613937Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"if __name__ == '__main__':\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T14:00:58.610173Z","iopub.execute_input":"2025-07-05T14:00:58.610568Z","iopub.status.idle":"2025-07-05T14:16:10.773661Z","shell.execute_reply.started":"2025-07-05T14:00:58.610542Z","shell.execute_reply":"2025-07-05T14:16:10.772148Z"}},"outputs":[{"name":"stdout","text":"สร้าง Landmarker สำหรับ CPU สำเร็จ\n\n--- เริ่มประมวลผลรูปภาพทั้งหมดและรวมเป็นไฟล์เดียว ---\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1751724058.632768      35 task_runner.cc:85] GPU suport is not available: INTERNAL: ; RET_CHECK failure (mediapipe/gpu/gl_context_egl.cc:84) egl_initializedUnable to initialize EGL\nW0000 00:00:1751724058.633811      35 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\nW0000 00:00:1751724058.644765     106 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751724058.683665     107 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Processing images:   0%|          | 0/31546 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6024838073bd41cebea87e7bc6b5d840"}},"metadata":{}},{"name":"stdout","text":"สร้างโฟลเดอร์ผลลัพธ์: /kaggle/working/output\n\nบันทึกข้อมูล Landmarker, label, และ split ทั้งหมดลงในไฟล์: '/kaggle/working/output/all_data_with_landmarks.npz' สำเร็จ\n\nการประมวลผลทั้งหมดเสร็จสิ้น! ตรวจสอบไฟล์ข้อมูลพิกัด (ในรูปแบบ .npz) ได้ที่โฟลเดอร์ '/kaggle/working/output'\n","output_type":"stream"}],"execution_count":13}]}